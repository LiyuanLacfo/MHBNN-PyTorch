{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "from custom_dataset import *\n",
    "from mhbn import *\n",
    "import time\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "print('Loading data')\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(500),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cpu or gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root path of data\n",
    "root = \"/home/alan/Desktop/view/classes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the batch size of train and validation\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dset_train = MultiViewDataSet(root, 'train', transform=transform)\n",
    "train_loader = DataLoader(dset_train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "dset_val = MultiViewDataSet(root, 'test', transform=transform)\n",
    "val_loader = DataLoader(dset_val, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, class_to_idx = dset_train.classes, dset_train.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of local features\n",
    "num_local_features = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n"
     ]
    }
   ],
   "source": [
    "model = mhbnn(True, len(classes), num_local_features)\n",
    "model.to(device)\n",
    "cudnn.benchmark = True\n",
    "print('Running on ' + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "lr_decay = 0.1\n",
    "lr_decay_freq = 30\n",
    "n_epochs = 100\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "best_acc = 0.0\n",
    "best_loss = 0.0\n",
    "start_epoch = 0\n",
    "print_freq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_path = './checkpoint'\n",
    "resume_ckp_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint():\n",
    "    global best_acc, start_epoch\n",
    "    # Load checkpoint.\n",
    "    print('\\n==> Loading checkpoint..')\n",
    "    assert os.path.isfile(resume_ckp_path), 'Error: no checkpoint file found!'\n",
    "\n",
    "    checkpoint = torch.load(resume_ckp_path)\n",
    "    best_acc = checkpoint['best_acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    train_size = len(train_loader)\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        # Convert from list of 3D to 4D\n",
    "        #convert to shape [batch_size, views, channels, width, height]\n",
    "        inputs = np.stack(inputs, axis=1)\n",
    "\n",
    "        inputs = torch.from_numpy(inputs)\n",
    "\n",
    "        inputs, targets = inputs.cuda(device), targets.cuda(device)\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) %  print_freq == 0:\n",
    "            print(\"\\tIter [%d/%d] Loss: %.4f\" % (i + 1, train_size, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(data_loader, is_test=False):\n",
    "    if is_test:\n",
    "       load_checkpoint()\n",
    "\n",
    "    # Eval\n",
    "    total = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            # Convert from list of 3D to 4D\n",
    "            inputs = np.stack(inputs, axis=1)\n",
    "\n",
    "            inputs = torch.from_numpy(inputs)\n",
    "\n",
    "            inputs, targets = inputs.cuda(device), targets.cuda(device)\n",
    "            inputs, targets = Variable(inputs), Variable(targets)\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            total_loss += loss\n",
    "            n += 1\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted.cpu() == targets.cpu()).sum()\n",
    "    avg_test_acc = 100 * correct / total\n",
    "    avg_loss = total_loss / n\n",
    "\n",
    "    return avg_test_acc, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume_ckp_path:\n",
    "    load_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------\n",
      "Epoch: [1/100]\n",
      "\tIter [10/2461] Loss: 3.6883\n",
      "\tIter [20/2461] Loss: 3.6968\n",
      "\tIter [30/2461] Loss: 3.6757\n",
      "\tIter [40/2461] Loss: 3.6590\n",
      "\tIter [50/2461] Loss: 3.5795\n",
      "\tIter [60/2461] Loss: 3.6115\n",
      "\tIter [70/2461] Loss: 3.4769\n",
      "\tIter [80/2461] Loss: 3.5802\n",
      "\tIter [90/2461] Loss: 3.6035\n",
      "\tIter [100/2461] Loss: 3.5225\n",
      "\tIter [110/2461] Loss: 3.0842\n",
      "\tIter [120/2461] Loss: 3.2837\n",
      "\tIter [130/2461] Loss: 3.5027\n",
      "\tIter [140/2461] Loss: 3.4837\n",
      "\tIter [150/2461] Loss: 3.4527\n",
      "\tIter [160/2461] Loss: 3.3980\n",
      "\tIter [170/2461] Loss: 3.3681\n",
      "\tIter [180/2461] Loss: 3.8943\n",
      "\tIter [190/2461] Loss: 3.4648\n",
      "\tIter [200/2461] Loss: 3.3594\n",
      "\tIter [210/2461] Loss: 3.6478\n",
      "\tIter [220/2461] Loss: 3.1512\n",
      "\tIter [230/2461] Loss: 3.6209\n",
      "\tIter [240/2461] Loss: 3.6048\n",
      "\tIter [250/2461] Loss: 2.7274\n",
      "\tIter [260/2461] Loss: 3.3344\n",
      "\tIter [270/2461] Loss: 3.4610\n",
      "\tIter [280/2461] Loss: 2.8464\n",
      "\tIter [290/2461] Loss: 2.9396\n",
      "\tIter [300/2461] Loss: 2.1151\n",
      "\tIter [310/2461] Loss: 3.2575\n",
      "\tIter [320/2461] Loss: 3.4276\n",
      "\tIter [330/2461] Loss: 2.8965\n",
      "\tIter [340/2461] Loss: 3.6647\n",
      "\tIter [350/2461] Loss: 2.5075\n",
      "\tIter [360/2461] Loss: 3.2576\n",
      "\tIter [370/2461] Loss: 3.6031\n",
      "\tIter [380/2461] Loss: 2.9933\n",
      "\tIter [390/2461] Loss: 3.3318\n",
      "\tIter [400/2461] Loss: 2.3040\n",
      "\tIter [410/2461] Loss: 1.8501\n",
      "\tIter [420/2461] Loss: 2.8625\n",
      "\tIter [430/2461] Loss: 3.5399\n",
      "\tIter [440/2461] Loss: 3.4031\n",
      "\tIter [450/2461] Loss: 2.1144\n",
      "\tIter [460/2461] Loss: 2.5815\n",
      "\tIter [470/2461] Loss: 3.5014\n",
      "\tIter [480/2461] Loss: 2.4705\n",
      "\tIter [490/2461] Loss: 3.2672\n",
      "\tIter [500/2461] Loss: 2.0191\n",
      "\tIter [510/2461] Loss: 2.7211\n",
      "\tIter [520/2461] Loss: 3.0238\n",
      "\tIter [530/2461] Loss: 2.9658\n",
      "\tIter [540/2461] Loss: 2.0828\n",
      "\tIter [550/2461] Loss: 2.2403\n",
      "\tIter [560/2461] Loss: 3.5115\n",
      "\tIter [570/2461] Loss: 2.2371\n",
      "\tIter [580/2461] Loss: 2.2086\n",
      "\tIter [590/2461] Loss: 2.1343\n",
      "\tIter [600/2461] Loss: 2.5443\n",
      "\tIter [610/2461] Loss: 2.0975\n",
      "\tIter [620/2461] Loss: 2.4053\n",
      "\tIter [630/2461] Loss: 2.4311\n",
      "\tIter [640/2461] Loss: 2.0281\n",
      "\tIter [650/2461] Loss: 1.8169\n",
      "\tIter [660/2461] Loss: 2.3873\n",
      "\tIter [670/2461] Loss: 2.9960\n",
      "\tIter [680/2461] Loss: 2.6585\n",
      "\tIter [690/2461] Loss: 1.2482\n",
      "\tIter [700/2461] Loss: 2.4506\n",
      "\tIter [710/2461] Loss: 2.4764\n",
      "\tIter [720/2461] Loss: 3.2262\n",
      "\tIter [730/2461] Loss: 2.0014\n",
      "\tIter [740/2461] Loss: 2.4954\n",
      "\tIter [750/2461] Loss: 1.3195\n",
      "\tIter [760/2461] Loss: 2.0731\n",
      "\tIter [770/2461] Loss: 2.9335\n",
      "\tIter [780/2461] Loss: 2.5198\n",
      "\tIter [790/2461] Loss: 1.4060\n",
      "\tIter [800/2461] Loss: 1.9878\n",
      "\tIter [810/2461] Loss: 1.7995\n",
      "\tIter [820/2461] Loss: 1.8057\n",
      "\tIter [830/2461] Loss: 1.5230\n",
      "\tIter [840/2461] Loss: 1.9433\n",
      "\tIter [850/2461] Loss: 3.0614\n",
      "\tIter [860/2461] Loss: 2.5209\n",
      "\tIter [870/2461] Loss: 1.7934\n",
      "\tIter [880/2461] Loss: 1.5844\n",
      "\tIter [890/2461] Loss: 1.9234\n",
      "\tIter [900/2461] Loss: 1.1359\n",
      "\tIter [910/2461] Loss: 2.1720\n",
      "\tIter [920/2461] Loss: 1.4051\n",
      "\tIter [930/2461] Loss: 3.1418\n",
      "\tIter [940/2461] Loss: 2.3136\n",
      "\tIter [950/2461] Loss: 2.5286\n",
      "\tIter [960/2461] Loss: 0.8228\n",
      "\tIter [970/2461] Loss: 0.9342\n",
      "\tIter [980/2461] Loss: 1.4226\n",
      "\tIter [990/2461] Loss: 2.0243\n",
      "\tIter [1000/2461] Loss: 1.2501\n",
      "\tIter [1010/2461] Loss: 0.7800\n",
      "\tIter [1020/2461] Loss: 3.7287\n",
      "\tIter [1030/2461] Loss: 0.8400\n",
      "\tIter [1040/2461] Loss: 1.7997\n",
      "\tIter [1050/2461] Loss: 3.1451\n",
      "\tIter [1060/2461] Loss: 0.8357\n",
      "\tIter [1070/2461] Loss: 4.0061\n",
      "\tIter [1080/2461] Loss: 2.9797\n",
      "\tIter [1090/2461] Loss: 2.6271\n",
      "\tIter [1100/2461] Loss: 1.2233\n",
      "\tIter [1110/2461] Loss: 1.6945\n",
      "\tIter [1120/2461] Loss: 3.0201\n",
      "\tIter [1130/2461] Loss: 1.9713\n",
      "\tIter [1140/2461] Loss: 2.4396\n",
      "\tIter [1150/2461] Loss: 1.6910\n",
      "\tIter [1160/2461] Loss: 3.5742\n",
      "\tIter [1170/2461] Loss: 0.4053\n",
      "\tIter [1180/2461] Loss: 0.8415\n",
      "\tIter [1190/2461] Loss: 1.9848\n",
      "\tIter [1200/2461] Loss: 1.3966\n",
      "\tIter [1210/2461] Loss: 1.2791\n",
      "\tIter [1220/2461] Loss: 1.5532\n",
      "\tIter [1230/2461] Loss: 1.7672\n",
      "\tIter [1240/2461] Loss: 1.2599\n",
      "\tIter [1250/2461] Loss: 1.2625\n",
      "\tIter [1260/2461] Loss: 1.3076\n",
      "\tIter [1270/2461] Loss: 1.2042\n",
      "\tIter [1280/2461] Loss: 2.1488\n",
      "\tIter [1290/2461] Loss: 1.2337\n",
      "\tIter [1300/2461] Loss: 2.6432\n",
      "\tIter [1310/2461] Loss: 2.0122\n",
      "\tIter [1320/2461] Loss: 2.3672\n",
      "\tIter [1330/2461] Loss: 3.6324\n",
      "\tIter [1340/2461] Loss: 1.9373\n",
      "\tIter [1350/2461] Loss: 1.9891\n",
      "\tIter [1360/2461] Loss: 2.1384\n",
      "\tIter [1370/2461] Loss: 2.0627\n",
      "\tIter [1380/2461] Loss: 1.2508\n",
      "\tIter [1390/2461] Loss: 1.7329\n",
      "\tIter [1400/2461] Loss: 0.9439\n",
      "\tIter [1410/2461] Loss: 1.8203\n",
      "\tIter [1420/2461] Loss: 1.7847\n",
      "\tIter [1430/2461] Loss: 1.5063\n",
      "\tIter [1440/2461] Loss: 2.8591\n",
      "\tIter [1450/2461] Loss: 1.5119\n",
      "\tIter [1460/2461] Loss: 3.2594\n",
      "\tIter [1470/2461] Loss: 3.1464\n",
      "\tIter [1480/2461] Loss: 2.6167\n",
      "\tIter [1490/2461] Loss: 2.0678\n",
      "\tIter [1500/2461] Loss: 1.1151\n",
      "\tIter [1510/2461] Loss: 3.3321\n",
      "\tIter [1520/2461] Loss: 1.1079\n",
      "\tIter [1530/2461] Loss: 2.0831\n",
      "\tIter [1540/2461] Loss: 1.8686\n",
      "\tIter [1550/2461] Loss: 1.3374\n",
      "\tIter [1560/2461] Loss: 1.8512\n",
      "\tIter [1570/2461] Loss: 1.5932\n",
      "\tIter [1580/2461] Loss: 2.1007\n",
      "\tIter [1590/2461] Loss: 0.8625\n",
      "\tIter [1600/2461] Loss: 2.4042\n",
      "\tIter [1610/2461] Loss: 1.9851\n",
      "\tIter [1620/2461] Loss: 2.6881\n",
      "\tIter [1630/2461] Loss: 1.5568\n",
      "\tIter [1640/2461] Loss: 1.7749\n",
      "\tIter [1650/2461] Loss: 3.2325\n",
      "\tIter [1660/2461] Loss: 2.4645\n",
      "\tIter [1670/2461] Loss: 1.4254\n",
      "\tIter [1680/2461] Loss: 1.7026\n",
      "\tIter [1690/2461] Loss: 2.0576\n",
      "\tIter [1700/2461] Loss: 2.1249\n",
      "\tIter [1710/2461] Loss: 1.9619\n",
      "\tIter [1720/2461] Loss: 1.4691\n",
      "\tIter [1730/2461] Loss: 1.5726\n",
      "\tIter [1740/2461] Loss: 0.7356\n",
      "\tIter [1750/2461] Loss: 0.4405\n",
      "\tIter [1760/2461] Loss: 2.4073\n",
      "\tIter [1770/2461] Loss: 2.2401\n",
      "\tIter [1780/2461] Loss: 0.6892\n",
      "\tIter [1790/2461] Loss: 1.4002\n",
      "\tIter [1800/2461] Loss: 0.4048\n",
      "\tIter [1810/2461] Loss: 2.0727\n",
      "\tIter [1820/2461] Loss: 0.6470\n",
      "\tIter [1830/2461] Loss: 1.2344\n",
      "\tIter [1840/2461] Loss: 0.8181\n",
      "\tIter [1850/2461] Loss: 1.9000\n",
      "\tIter [1860/2461] Loss: 1.0141\n",
      "\tIter [1870/2461] Loss: 0.9508\n",
      "\tIter [1880/2461] Loss: 3.5383\n",
      "\tIter [1890/2461] Loss: 1.9355\n",
      "\tIter [1900/2461] Loss: 1.1119\n",
      "\tIter [1910/2461] Loss: 2.2507\n",
      "\tIter [1920/2461] Loss: 0.7424\n",
      "\tIter [1930/2461] Loss: 1.1117\n",
      "\tIter [1940/2461] Loss: 1.2224\n",
      "\tIter [1950/2461] Loss: 1.3931\n",
      "\tIter [1960/2461] Loss: 1.9083\n",
      "\tIter [1970/2461] Loss: 2.5647\n",
      "\tIter [1980/2461] Loss: 0.6747\n",
      "\tIter [1990/2461] Loss: 1.4130\n",
      "\tIter [2000/2461] Loss: 1.6327\n",
      "\tIter [2010/2461] Loss: 1.4419\n",
      "\tIter [2020/2461] Loss: 0.4077\n",
      "\tIter [2030/2461] Loss: 1.4769\n",
      "\tIter [2040/2461] Loss: 1.1526\n",
      "\tIter [2050/2461] Loss: 2.0156\n",
      "\tIter [2060/2461] Loss: 2.2939\n",
      "\tIter [2070/2461] Loss: 0.7684\n",
      "\tIter [2080/2461] Loss: 1.1506\n",
      "\tIter [2090/2461] Loss: 1.2534\n",
      "\tIter [2100/2461] Loss: 0.8084\n",
      "\tIter [2110/2461] Loss: 1.2233\n",
      "\tIter [2120/2461] Loss: 1.4552\n",
      "\tIter [2130/2461] Loss: 2.0513\n",
      "\tIter [2140/2461] Loss: 2.3375\n",
      "\tIter [2150/2461] Loss: 1.7544\n",
      "\tIter [2160/2461] Loss: 1.7033\n",
      "\tIter [2170/2461] Loss: 0.8690\n",
      "\tIter [2180/2461] Loss: 1.9208\n",
      "\tIter [2190/2461] Loss: 1.1514\n",
      "\tIter [2200/2461] Loss: 1.3290\n",
      "\tIter [2210/2461] Loss: 1.9603\n",
      "\tIter [2220/2461] Loss: 1.6498\n",
      "\tIter [2230/2461] Loss: 3.1993\n",
      "\tIter [2240/2461] Loss: 1.8922\n",
      "\tIter [2250/2461] Loss: 0.7850\n",
      "\tIter [2260/2461] Loss: 0.5452\n",
      "\tIter [2270/2461] Loss: 0.7313\n",
      "\tIter [2280/2461] Loss: 2.4882\n",
      "\tIter [2290/2461] Loss: 1.8277\n",
      "\tIter [2300/2461] Loss: 0.7386\n",
      "\tIter [2310/2461] Loss: 1.8763\n",
      "\tIter [2320/2461] Loss: 0.3686\n",
      "\tIter [2330/2461] Loss: 0.3019\n",
      "\tIter [2340/2461] Loss: 1.8997\n",
      "\tIter [2350/2461] Loss: 1.5108\n",
      "\tIter [2360/2461] Loss: 1.1133\n",
      "\tIter [2370/2461] Loss: 0.3528\n",
      "\tIter [2380/2461] Loss: 1.3412\n",
      "\tIter [2390/2461] Loss: 1.7411\n",
      "\tIter [2400/2461] Loss: 1.2908\n",
      "\tIter [2410/2461] Loss: 0.6166\n",
      "\tIter [2420/2461] Loss: 0.4670\n",
      "\tIter [2430/2461] Loss: 1.0936\n",
      "\tIter [2440/2461] Loss: 1.7904\n",
      "\tIter [2450/2461] Loss: 1.8195\n",
      "\tIter [2460/2461] Loss: 0.9394\n",
      "Time taken: 226.65 sec.\n",
      "\n",
      "Evaluation:\n",
      "\tVal Acc: 65.00 - Loss: 1.1527\n",
      "\tCurrent best  val acc: 0.00\n",
      "\tSaving checkpoint - Acc: 65.00\n",
      "\n",
      "-----------------------------------\n",
      "Epoch: [2/100]\n",
      "\tIter [10/2461] Loss: 1.2999\n",
      "\tIter [20/2461] Loss: 2.0038\n",
      "\tIter [30/2461] Loss: 1.0422\n",
      "\tIter [40/2461] Loss: 2.2150\n",
      "\tIter [50/2461] Loss: 0.6337\n",
      "\tIter [60/2461] Loss: 2.1248\n",
      "\tIter [70/2461] Loss: 1.0289\n",
      "\tIter [80/2461] Loss: 2.0062\n",
      "\tIter [90/2461] Loss: 0.9409\n",
      "\tIter [100/2461] Loss: 1.1977\n",
      "\tIter [110/2461] Loss: 1.5402\n",
      "\tIter [120/2461] Loss: 1.2572\n",
      "\tIter [130/2461] Loss: 2.0992\n",
      "\tIter [140/2461] Loss: 0.2727\n",
      "\tIter [150/2461] Loss: 0.8716\n",
      "\tIter [160/2461] Loss: 1.2568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIter [170/2461] Loss: 0.4038\n",
      "\tIter [180/2461] Loss: 1.5911\n",
      "\tIter [190/2461] Loss: 1.8787\n",
      "\tIter [200/2461] Loss: 0.9013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "Process Process-5:\n",
      "  File \"/home/alan/anaconda3/envs/ml/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alan/anaconda3/envs/ml/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alan/anaconda3/envs/ml/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/alan/anaconda3/envs/ml/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/alan/anaconda3/envs/ml/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alan/Desktop/MHBN/custom_dataset.py\", line 43, in __getitem__\n",
      "    im = self.transform(im)\n",
      "  File \"/home/alan/anaconda3/envs/ml/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alan/anaconda3/envs/ml/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/alan/anaconda3/envs/ml/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alan/anaconda3/envs/ml/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\", line 175, in __call__\n",
      "    return F.resize(img, self.size, self.interpolation)\n",
      "  File \"/home/alan/anaconda3/envs/ml/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/alan/anaconda3/envs/ml/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/alan/Desktop/MHBN/custom_dataset.py\", line 43, in __getitem__\n",
      "    im = self.transform(im)\n",
      "  File \"/home/alan/anaconda3/envs/ml/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\", line 175, in __call__\n",
      "    return F.resize(img, self.size, self.interpolation)\n",
      "  File \"/home/alan/anaconda3/envs/ml/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/functional.py\", line 204, in resize\n",
      "    return img.resize((ow, oh), interpolation)\n",
      "  File \"/home/alan/anaconda3/envs/ml/lib/python3.6/site-packages/PIL/Image.py\", line 1765, in resize\n",
      "    return self._new(self.im.resize(size, resample, box))\n",
      "  File \"/home/alan/anaconda3/envs/ml/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/functional.py\", line 204, in resize\n",
      "    return img.resize((ow, oh), interpolation)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/alan/anaconda3/envs/ml/lib/python3.6/site-packages/PIL/Image.py\", line 1765, in resize\n",
      "    return self._new(self.im.resize(size, resample, box))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-98d1265f1571>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time taken: %.2f sec.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-392d35a33e25>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, n_epochs):\n",
    "    print('\\n-----------------------------------')\n",
    "    print('Epoch: [%d/%d]' % (epoch+1, n_epochs))\n",
    "    start = time.time()\n",
    "\n",
    "    model.train()\n",
    "    train()\n",
    "    print('Time taken: %.2f sec.' % (time.time() - start))\n",
    "\n",
    "    model.eval()\n",
    "    avg_test_acc, avg_loss = eval(val_loader)\n",
    "\n",
    "    print('\\nEvaluation:')\n",
    "    print('\\tVal Acc: %.2f - Loss: %.4f' % (avg_test_acc.item(), avg_loss.item()))\n",
    "    print('\\tCurrent best  val acc: %.2f' % best_acc)\n",
    "    \n",
    "\n",
    "    # Log epoch to tensorboard\n",
    "    # See log using: tensorboard --logdir='logs' --port=6006\n",
    "#     util.logEpoch(logger, model, epoch + 1, avg_loss, avg_test_acc)\n",
    "\n",
    "    # Save model\n",
    "    if avg_test_acc > best_acc:\n",
    "        print('\\tSaving checkpoint - Acc: %.2f' % avg_test_acc)\n",
    "        best_acc = avg_test_acc\n",
    "        best_loss = avg_loss\n",
    "        util.save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'acc': avg_test_acc,\n",
    "            'best_acc': best_acc,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, 'mhbnn_'+str(num_local_features))\n",
    "\n",
    "    # Decaying Learning Rate\n",
    "    if (epoch + 1) % lr_decay_freq == 0:\n",
    "        lr *= lr_decay\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        print('Learning rate:', lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
